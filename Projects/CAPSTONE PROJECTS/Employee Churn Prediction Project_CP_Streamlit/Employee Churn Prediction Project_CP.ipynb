{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg_ZAS0B2slE"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EjVhtzq2slH"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqV3cXW-2slL"
   },
   "source": [
    "Welcome to \"***Employee Churn Analysis Project***\". This is the second project of Capstone Project Series, which you will be able to build your own classification models for a variety of business settings. \n",
    "\n",
    "Also you will learn what is Employee Churn?, How it is different from customer churn, Exploratory data analysis and visualization of employee churn dataset using ***matplotlib*** and ***seaborn***, model building and evaluation using python ***scikit-learn*** package. \n",
    "\n",
    "You will be able to implement classification techniques in Python. Using Scikit-Learn allowing you to successfully make predictions with the ***Random Forest, Gradient Descent Boosting , KNN algorithms.***\n",
    "\n",
    "At the end of the project, you will have the opportunity to deploy your model using ***Streamlit.***\n",
    "\n",
    "Before diving into the project, please take a look at the determines and project structure.\n",
    "\n",
    "- NOTE: This project assumes that you already know the basics of coding in Python and are familiar with model deployement as well as the theory behind K-Means, Gradient Boosting , KNN, Random Forest, and Confusion Matrices. You can try more models and methods beside these to improve your model metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oRnVXpS2slN"
   },
   "source": [
    "# #Determines\n",
    "In this project you have HR data of a company. A study is requested from you to predict which employee will churn by using this data.\n",
    "\n",
    "The HR dataset has 14,999 samples. In the given dataset, you have two types of employee one who stayed and another who left the company.\n",
    "\n",
    "You can describe 10 attributes in detail as:\n",
    "- ***satisfaction_level:*** It is employee satisfaction point, which ranges from 0-1.\n",
    "- ***last_evaluation:*** It is evaluated performance by the employer, which also ranges from 0-1.\n",
    "- ***number_projects:*** How many of projects assigned to an employee?\n",
    "- ***average_monthly_hours:*** How many hours in averega an employee worked in a month?\n",
    "- **time_spent_company:** time_spent_company means employee experience. The number of years spent by an employee in the company.\n",
    "- ***work_accident:*** Whether an employee has had a work accident or not.\n",
    "- ***promotion_last_5years:*** Whether an employee has had a promotion in the last 5 years or not.\n",
    "- ***Departments:*** Employee's working department/division.\n",
    "- ***Salary:*** Salary level of the employee such as low, medium and high.\n",
    "- ***left:*** Whether the employee has left the company or not.\n",
    "\n",
    "First of all, to observe the structure of the data, outliers, missing values and features that affect the target variable, you must use exploratory data analysis and data visualization techniques. \n",
    "\n",
    "Then, you must perform data pre-processing operations such as ***Scaling*** and ***Label Encoding*** to increase the accuracy score of Gradient Descent Based or Distance-Based algorithms. you are asked to perform ***Cluster Analysis*** based on the information you obtain during exploratory data analysis and data visualization processes. \n",
    "\n",
    "The purpose of clustering analysis is to cluster data with similar characteristics. You are asked to use the ***K-means*** algorithm to make cluster analysis. However, you must provide the K-means algorithm with information about the number of clusters it will make predictions. Also, the data you apply to the K-means algorithm must be scaled. In order to find the optimal number of clusters, you are asked to use the ***Elbow method***. Briefly, try to predict the set to which individuals are related by using K-means and evaluate the estimation results.\n",
    "\n",
    "Once the data is ready to be applied to the model, you must ***split the data into train and test***. Then build a model to predict whether employees will churn or not. Train your models with your train set, test the success of your model with your test set. \n",
    "\n",
    "Try to make your predictions by using the algorithms ***Gradient Boosting Classifier***, ***K Neighbors Classifier***, ***Random Forest Classifier***. You can use the related modules of the ***scikit-learn*** library. You can use scikit-learn ***Confusion Metrics*** module for accuracy calculation. You can use the ***Yellowbrick*** module for model selection and visualization.\n",
    "\n",
    "In the final step, you will deploy your model using Streamlit tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97xzRLNj2slO"
   },
   "source": [
    "# #Tasks\n",
    "\n",
    "#### 1. Exploratory Data Analysis\n",
    "- Importing Modules\n",
    "- Loading Dataset\n",
    "- Data Insigts\n",
    "\n",
    "#### 2. Data Visualization\n",
    "- Employees Left\n",
    "- Determine Number of Projects\n",
    "- Determine Time Spent in Company\n",
    "- Subplots of Features\n",
    "\n",
    "#### 3. Data Pre-Processing\n",
    "- Scaling\n",
    "- Label Encoding\n",
    "\n",
    "#### 4. Cluster Analysis\n",
    "- Find the optimal number of clusters (k) using the elbow method for for K-means.\n",
    "- Determine the clusters by using K-Means then Evaluate predicted results.\n",
    "\n",
    "#### 5. Model Building\n",
    "- Split Data as Train and Test set\n",
    "- Built Gradient Boosting Classifier, Evaluate Model Performance and Predict Test Data\n",
    "- Built K Neighbors Classifier and Evaluate Model Performance and Predict Test Data\n",
    "- Built Random Forest Classifier and Evaluate Model Performance and Predict Test Data\n",
    "\n",
    "#### 6. Model Deployement\n",
    "\n",
    "- Save and Export the Model as .pkl\n",
    "- Save and Export Variables as .pkl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLTGi7q02slP"
   },
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis is an initial process of analysis, in which you can summarize characteristics of data such as pattern, trends, outliers, and hypothesis testing using descriptive statistics and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyrWBiyM2sld"
   },
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn(\"this will not show\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS9n2J9-2sln"
   },
   "source": [
    "### Loading Dataset\n",
    "\n",
    "Let's first load the required HR dataset using pandas's \"read_csv\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.11             0.88               7   \n",
       "3                    0.72             0.87               5   \n",
       "4                    0.37             0.52               2   \n",
       "...                   ...              ...             ...   \n",
       "14994                0.40             0.57               2   \n",
       "14995                0.37             0.48               2   \n",
       "14996                0.37             0.53               2   \n",
       "14997                0.11             0.96               6   \n",
       "14998                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       272                   4              0     1   \n",
       "3                       223                   5              0     1   \n",
       "4                       159                   3              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14994                   151                   3              0     1   \n",
       "14995                   160                   3              0     1   \n",
       "14996                   143                   3              0     1   \n",
       "14997                   280                   4              0     1   \n",
       "14998                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years Departments   salary  \n",
       "0                          0        sales     low  \n",
       "1                          0        sales  medium  \n",
       "2                          0        sales  medium  \n",
       "3                          0        sales     low  \n",
       "4                          0        sales     low  \n",
       "...                      ...          ...     ...  \n",
       "14994                      0      support     low  \n",
       "14995                      0      support     low  \n",
       "14996                      0      support     low  \n",
       "14997                      0      support     low  \n",
       "14998                      0      support     low  \n",
       "\n",
       "[14999 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"time_spend_company\" : \"time_spent_company\", \"average_montly_hours\" : \"average_monthly_hours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_monthly_hours</th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_monthly_hours  \\\n",
       "0                0.38             0.53               2                    157   \n",
       "1                0.80             0.86               5                    262   \n",
       "2                0.11             0.88               7                    272   \n",
       "3                0.72             0.87               5                    223   \n",
       "4                0.37             0.52               2                    159   \n",
       "\n",
       "   time_spent_company  work_accident  left  promotion_last_5years departments  \\\n",
       "0                   3              0     1                      0       sales   \n",
       "1                   6              0     1                      0       sales   \n",
       "2                   4              0     1                      0       sales   \n",
       "3                   5              0     1                      0       sales   \n",
       "4                   3              0     1                      0       sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nyUCvXyU2slQ"
   },
   "outputs": [],
   "source": [
    "def explain(attribute):\n",
    "    features=  {\n",
    "        \"satisfaction_level\" : \"It is employee satisfaction point, which ranges from 0-1\",\n",
    "        \"last_evaluation\" : \"It is evaluated performance by the employer, which also ranges from 0-1\",\n",
    "        \"number_projects\" : \"How many of projects assigned to an employee?\",\n",
    "        \"average_monthly_hours\" : \"How many hours in averega an employee worked in a month?\",\n",
    "        \"time_spent_company\" : \"The number of years spent by an employee in the company - experience -\",\n",
    "        \"work_accident\" : \"Whether an employee has had a work accident or not\",\n",
    "        \"promotion_last_5years\" : \"Whether an employee has had a promotion in the last 5 years or not\",\n",
    "        \"departments\" : \"Employee's working department/division\",\n",
    "        \"salary\" : \"Salary level of the employee such as low, medium and high\",\n",
    "        \"left\" : \"Whether the employee has left the company or not\"\n",
    "                }\n",
    "    return features[attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is evaluated performance by the employer, which also ranges from 0-1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain(\"last_evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   satisfaction_level     14999 non-null  float64\n",
      " 1   last_evaluation        14999 non-null  float64\n",
      " 2   number_project         14999 non-null  int64  \n",
      " 3   average_monthly_hours  14999 non-null  int64  \n",
      " 4   time_spent_company     14999 non-null  int64  \n",
      " 5   work_accident          14999 non-null  int64  \n",
      " 6   left                   14999 non-null  int64  \n",
      " 7   promotion_last_5years  14999 non-null  int64  \n",
      " 8   departments            14999 non-null  object \n",
      " 9   salary                 14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    11991\n",
      "True      3008\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "False    79.94533\n",
      "True     20.05467\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().value_counts())\n",
    "print(\"\\n\")\n",
    "print(df.duplicated().value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop_duplicates()  #Model tahmin skorları duplicates silindiğinde azalıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feat_uniques(x):\n",
    "    max = {}\n",
    "    for i in x.columns:\n",
    "        a = x[i].nunique()\n",
    "        max[i] = a\n",
    "    for w in sorted(max, key=max.get, reverse=True):\n",
    "        print(f\"{w} columns has {max[w]} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_monthly_hours columns has 215 unique values\n",
      "satisfaction_level columns has 92 unique values\n",
      "last_evaluation columns has 65 unique values\n",
      "departments columns has 10 unique values\n",
      "time_spent_company columns has 8 unique values\n",
      "number_project columns has 6 unique values\n",
      "salary columns has 3 unique values\n",
      "work_accident columns has 2 unique values\n",
      "left columns has 2 unique values\n",
      "promotion_last_5years columns has 2 unique values\n"
     ]
    }
   ],
   "source": [
    "feat_uniques(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'average_monthly_hours' column differs between 96 and 310\n"
     ]
    }
   ],
   "source": [
    "print(\"'average_monthly_hours' column differs between {} and {}\".format(df.average_monthly_hours.min(), df.average_monthly_hours.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rvS39ktq2slt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2_unique_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work_accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>promotion_last_5years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2_unique_values\n",
       "1          work_accident\n",
       "2                   left\n",
       "3  promotion_last_5years"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_uniques = pd.DataFrame(df.columns[df.nunique() == 2]).rename(columns = {0: '2_unique_values'}, index={0:1, 1:2, 2:3})\n",
    "two_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.isnull().any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This is Great!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction_level</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.248631</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_evaluation</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_project</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>3.803054</td>\n",
       "      <td>1.232592</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_monthly_hours</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>201.050337</td>\n",
       "      <td>49.943099</td>\n",
       "      <td>96.00</td>\n",
       "      <td>156.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent_company</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>3.498233</td>\n",
       "      <td>1.460136</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_accident</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.425924</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.144281</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean        std    min     25%     50%  \\\n",
       "satisfaction_level     14999.0    0.612834   0.248631   0.09    0.44    0.64   \n",
       "last_evaluation        14999.0    0.716102   0.171169   0.36    0.56    0.72   \n",
       "number_project         14999.0    3.803054   1.232592   2.00    3.00    4.00   \n",
       "average_monthly_hours  14999.0  201.050337  49.943099  96.00  156.00  200.00   \n",
       "time_spent_company     14999.0    3.498233   1.460136   2.00    3.00    3.00   \n",
       "work_accident          14999.0    0.144610   0.351719   0.00    0.00    0.00   \n",
       "left                   14999.0    0.238083   0.425924   0.00    0.00    0.00   \n",
       "promotion_last_5years  14999.0    0.021268   0.144281   0.00    0.00    0.00   \n",
       "\n",
       "                          75%    max  \n",
       "satisfaction_level       0.82    1.0  \n",
       "last_evaluation          0.87    1.0  \n",
       "number_project           5.00    7.0  \n",
       "average_monthly_hours  245.00  310.0  \n",
       "time_spent_company       4.00   10.0  \n",
       "work_accident            0.00    1.0  \n",
       "left                     0.00    1.0  \n",
       "promotion_last_5years    0.00    1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "sns.boxplot(df.time_spent_company);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(dff:pd.DataFrame, col_name:str, p=1.5) ->int:\n",
    "\n",
    "    first_quartile = np.percentile(np.array(dff[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(dff[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "                      \n",
    "    upper_limit = third_quartile+(p*IQR)\n",
    "    lower_limit = first_quartile-(p*IQR)\n",
    "    outlier_count = 0\n",
    "                      \n",
    "    for value in dff[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "    return lower_limit, upper_limit, outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers for 2*IQR after Logarithmed\n",
      "\n",
      "564 outliers in 'time_spent_company'\n",
      "2169 outliers in 'work_accident'\n",
      "3571 outliers in 'left'\n",
      "319 outliers in 'promotion_last_5years'\n",
      "\n",
      "6623 OUTLIERS TOTALLY\n"
     ]
    }
   ],
   "source": [
    "iqr=2\n",
    "print(f\"Number of Outliers for {iqr}*IQR after Logarithmed\\n\")\n",
    "\n",
    "total=0\n",
    "for col in df.iloc[:,:-2]:\n",
    "    if detect_outliers(df, col)[2] > 0:\n",
    "        outliers=detect_outliers(df, col, iqr)[2]\n",
    "        total+=outliers\n",
    "        print(\"{} outliers in '{}'\".format(outliers,col))\n",
    "print(\"\\n{} OUTLIERS TOTALLY\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_spent_company</th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.565513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.348064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.291086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.246159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.016338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_spent_company      left\n",
       "3                   5  0.565513\n",
       "2                   4  0.348064\n",
       "4                   6  0.291086\n",
       "1                   3  0.246159\n",
       "0                   2  0.016338\n",
       "5                   7  0.000000\n",
       "6                   8  0.000000\n",
       "7                  10  0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['left', 'time_spent_company']].groupby(['time_spent_company'], as_index=False).mean().sort_values(by='left', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Çoğunlukla 3-6 yıl arası çalışanlar ayrılma eğiliminde olduğundan 6 yıl üzerindeki outlier'ları önemsemedik***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whose_list = [\"time_spent_company\", \"number_project\", \"work_accident\", \"left\", \"departments\", \"salary\", \"promotion_last_5years\"]\n",
    "for i in whose_list:\n",
    "    v = df[i].value_counts()\n",
    "    vv = df[i].value_counts(normalize=True)\n",
    "    print(f'Value counts of \"{i}\" column')\n",
    "    print(v)\n",
    "    print(\"-\" * 50)\n",
    "    print(f'Percentage of the Value counts of \"{i}\" column')\n",
    "    print(vv * 100)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "sns.heatmap(df.corr(), cmap='magma', annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc8t0m9u2sl2"
   },
   "source": [
    "### Data Insights\n",
    "\n",
    "In the given dataset, you have two types of employee one who stayed and another who left the company. So, you can divide data into two groups and compare their characteristics. Here, you can find the average of both the groups using groupby() and mean() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6), dpi=100)\n",
    "sns.heatmap(df.groupby(\"left\").corr(), cmap='magma', annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4), dpi=100)\n",
    "sns.barplot(x=df.corr()['left'].sort_values(ascending=False)[1:].index,\n",
    "            y = df.corr()['left'].sort_values(ascending=False)[1:].values,\n",
    "            palette='prism')\n",
    "plt.title(\"Feature Correlation to Churn (Left)\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"left\").describe().T.rename(columns = {0:\"Stayed\", 1:\"Left\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('left').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***İşten ayrılanlar, ayrılmayanlara kıyasla daha düşük tatmin seviyesine, daha düşük maaşa, daha düşük terfi alma imkanlarına ve daha yüksek çalışma saatlerine sahipler***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PsO9Iew2smG"
   },
   "source": [
    "## 2. Data Visualization\n",
    "\n",
    "You can search for answers to the following questions using data visualization methods. Based on these responses, you can develop comments about the factors that cause churn.\n",
    "- How does the promotion status affect employee churn?\n",
    "- How does years of experience affect employee churn?\n",
    "- How does workload affect employee churn?\n",
    "- How does the salary level affect employee churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRQhFwtq2smI"
   },
   "source": [
    "### Employees Left\n",
    "\n",
    "Let's check how many employees were left?\n",
    "Here, you can plot a bar graph using Matplotlib. The bar graph is suitable for showing discrete variable counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "g = df.left.value_counts().plot(kind=\"bar\", color=[\"green\", \"red\"], width=0.3)\n",
    "plt.title('General Distribution of Left Employees', fontsize = 15)\n",
    "plt.xlabel(\"Stayed & Left\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.0, p.get_height()+100));\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(df['left'].value_counts().sort_index(), autopct='%1.1f%%', startangle=0, colors=[\"green\", \"red\"] )\n",
    "plt.legend(df['left'].value_counts().sort_index().index, bbox_to_anchor=(1.45,0.5), loc='center')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "g = sns.countplot(data=df, x=\"salary\", order=df[\"salary\"].value_counts().index, palette=\"prism\")\n",
    "plt.title('Distribution of Salaries', fontsize = 15)\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Employees\")\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.25, p.get_height()+ 50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=100)\n",
    "sns.scatterplot(data=df, y=\"average_monthly_hours\", x=\"satisfaction_level\", hue=\"left\", palette=[\"orange\", \"blue\"])\n",
    "plt.legend(bbox_to_anchor=(1.10,1.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vn6NHSZE2smY"
   },
   "source": [
    "### Number of Projects\n",
    "\n",
    "Similarly, you can also plot a bar graph to count the number of employees deployed on how many projects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGyyJcUP2sma"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "g = sns.countplot(data = df, x=\"number_project\", order = df.number_project.value_counts().index, palette=\"magma\")\n",
    "plt.title('Distribution of Projects', fontsize = 15)\n",
    "plt.xlabel(\"Projects\")\n",
    "plt.ylabel(\"Employees\")\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.20, p.get_height()+30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Çoğunlukla 2-5 arası projeye katılıım sözkonusu. 5'den fazla projeye katılım sayısında ciddi düşüş var***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48X9SO4v2smj"
   },
   "source": [
    "### Time Spent in Company\n",
    "\n",
    "Similarly, you can also plot a bar graph to count the number of employees have based on how much experience?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"time_spent_company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW-HRwfU2sml"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "g = sns.countplot(data = df, x=\"time_spent_company\", order = df[\"time_spent_company\"].value_counts().index, palette=\"magma\")\n",
    "plt.title('Distribution of Experiences', fontsize = 15)\n",
    "plt.xlabel(\"Experience\")\n",
    "plt.ylabel(\"Employees\")\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.2, p.get_height()+30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Çoğunlukla çalışanlar 2-4 yıl arası tecrübeye sahipler. 3 ve 4 yıl tücrübeliler arasında ciddi bir fark sözkonusu. 6 yıl üzeri çalışanlarda firmaya aidiyet veya duygusal yakınlık hissedilmesi sözkonusu olabilir***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "g = sns.countplot(data = df, x=\"departments\", order = df[\"departments\"].value_counts().index, palette=\"magma\")\n",
    "plt.title('Distribution of Departments', fontsize = 15)\n",
    "plt.xlabel(\"Departments\")\n",
    "plt.ylabel(\"Employees\")\n",
    "plt.xticks(rotation=45);\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.1, p.get_height()+30));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Satış, Teknik ve Destek en çok çalışana sahip ilk 3 birim iken, yönetim kademesi en az çalışana sahip birim***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(\"average_monthly_hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4), dpi=100)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "g = sns.countplot(data = df, x=\"promotion_last_5years\", order = df[\"promotion_last_5years\"].value_counts().index, palette=[\"darkorange\", \"green\"])\n",
    "plt.title('Distribution of Promotions in Last 5 years', fontsize = 15)\n",
    "plt.xlabel(\"Promotion\")\n",
    "\n",
    "for p in g.patches:\n",
    "    g.annotate((p.get_height()), (p.get_x()+0.2, p.get_height()+ 75));\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(df['promotion_last_5years'].value_counts().sort_index(), autopct='%1.1f%%', startangle=0, colors=[\"darkorange\", \"green\"], explode = (0.05, 0.05), shadow=False)\n",
    "plt.legend(df['promotion_last_5years'].value_counts().sort_index().index, bbox_to_anchor=(1.45,0.5), loc='center right')\n",
    "explode = (0, 0.1, 0, 0)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Son 5 yıl içinde sadece %2'lik bir kesimin terfi almış olmasının, işten ayrılma oranını arttırdığı değerlendirilmektedir***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 0),'last_evaluation'] , color='darkblue',shade=True,label='stayed')\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 1),'last_evaluation'] , color='darkred',shade=True, label='left')\n",
    "ax.set(xlabel='Employee Evaluation', ylabel='Frequency')\n",
    "plt.title('Employee Evaluation')\n",
    "plt.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***İşten ayrılanların hem yüksek hem de düşük performans sergileyebildikleri görülmekte. İşten ayrılmayanlar için ideal bandın 0.5 üzeri olduğu söylenebilir*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 0),'average_monthly_hours'] , color='darkblue',shade=True,label='stayed')\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 1),'average_monthly_hours'] , color='darkred',shade=True, label='left')\n",
    "ax.set(xlabel='Employee Evaluation', ylabel='Frequency')\n",
    "plt.title(\"Average Monthly Working Hours\")\n",
    "ax.axvline(x=df[\"average_monthly_hours\"].mean(), color=\"green\", ls=\"--\")\n",
    "plt.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***İşten ayrılanların hem yüksek hem de düşük çalışma saatlerine sahip olabildikleri görülmekte. İşten ayrılmayanlar için ideal bandın 130 ila 270 saat olduğu söylenebilir*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 0),'satisfaction_level'] , color='darkblue',shade=True,label='stayed')\n",
    "ax=sns.kdeplot(df.loc[(df['left'] == 1),'satisfaction_level'] , color='darkred',shade=True, label='left')\n",
    "ax.set(xlabel='Satisfaction', ylabel='Frequency')\n",
    "plt.title('Employee Satisfaction')\n",
    "plt.legend(loc=\"upper right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***İşten ayrılanların her derecede tatmin seviyelerine sahip olabikleri görülmekte. İşten ayrılmayanlar için ideal bandın 0.5 üzeri olduğu söylenebilir*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEbtBv3q2smq"
   },
   "source": [
    "### Subplots of Features\n",
    "\n",
    "You can use the methods of the matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['number_project','time_spent_company','work_accident','left', 'promotion_last_5years','departments','salary']\n",
    "fig=plt.subplots(figsize=(15,25), dpi=100)\n",
    "for i, j in enumerate(features):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.subplots_adjust(hspace = 1.0)\n",
    "    sns.countplot(x=j, data=df, palette=\"magma\")\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['number_project','time_spent_company','work_accident','left', 'promotion_last_5years','departments','salary']\n",
    "fig=plt.subplots(figsize=(15,25), dpi=100)\n",
    "for i, j in enumerate(features):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.subplots_adjust(hspace = 1.0)\n",
    "    sns.countplot(x=j, data=df, hue=\"left\", palette=\"magma\")\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(ncols=3, figsize=(14,5), dpi=150)\n",
    "\n",
    "sns.distplot(df.satisfaction_level, kde=True, color=\"b\", ax=axes[0]).set_title('Distribution of Satisfaction')\n",
    "\n",
    "sns.distplot(df.last_evaluation, kde=True, color=\"r\", ax=axes[1]).set_title('Distribution of Evaluation')\n",
    "\n",
    "sns.distplot(df.average_monthly_hours, kde=True, color=\"green\", ax=axes[2]).set_title('Distribution of Average Monthly Hours');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***Düşük ile yüksek derece tatmin seviyeleri dağılımları arasında ciddi bir fark bulunmaktadır***\n",
    "* ***Performans değerlendirmesi ile aylık ortalama çalışma saatleri dağılımları çok benzerlik göstermektedir. Az saat çalışma ortalaması olan bir işçinin performans değerlendirmesi de düşük olmaktadır. Ya da tam tersi***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36OyDJyx2sm2"
   },
   "source": [
    "## 3. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iN94C5P42sm4"
   },
   "source": [
    "#### Scaling\n",
    "\n",
    "Some machine learning algorithms are sensitive to feature scaling while others are virtually invariant to it. Machine learning algorithms like linear regression, logistic regression, neural network, etc. that use gradient descent as an optimization technique require data to be scaled. Also distance algorithms like KNN, K-means, and SVM are most affected by the range of features. This is because behind the scenes they are using distances between data points to determine their similarity.\n",
    "\n",
    "Scaling Types:\n",
    "- Normalization: Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "\n",
    "- Standardization: Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HXszRiq2sm4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary']=df.salary.map({\"low\":0, \"medium\":1, \"high\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df.drop(columns=[\"left\"]))\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = scaler.fit_transform(df_dummies)\n",
    "df_new = pd.DataFrame(df_scaled, columns=df_dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8-SVBoq2snA"
   },
   "source": [
    "#### Label Encoding\n",
    "\n",
    "Lots of machine learning algorithms require numerical input data, so you need to represent categorical columns in a numerical column. In order to encode this data, you could map each value to a number. e.g. Salary column's value can be represented as low:0, medium:1, and high:2. This process is known as label encoding, and sklearn conveniently will do this for you using LabelEncoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pVP9UBQ2snC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "df_le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Gp2f7q2snF"
   },
   "source": [
    "## 4. Cluster Analysis\n",
    "\n",
    "- Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\n",
    "\n",
    "    [Cluster Analysis](https://en.wikipedia.org/wiki/Cluster_analysis)\n",
    "\n",
    "    [Cluster Analysis2](https://realpython.com/k-means-clustering-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWQx_bhw2snG"
   },
   "source": [
    "#### The Elbow Method\n",
    "\n",
    "- \"Elbow Method\" can be used to find the optimum number of clusters in cluster analysis. The elbow method is used to determine the optimal number of clusters in k-means clustering. The elbow method plots the value of the cost function produced by different values of k. If k increases, average distortion will decrease, each cluster will have fewer constituent instances, and the instances will be closer to their respective centroids. However, the improvements in average distortion will decline as k increases. The value of k at which improvement in distortion declines the most is called the elbow, at which we should stop dividing the data into further clusters.\n",
    "\n",
    "    [The Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)\n",
    "\n",
    "    [The Elbow Method2](https://medium.com/@mudgalvivek2911/machine-learning-clustering-elbow-method-4e8c2b404a5d)\n",
    "\n",
    "    [KMeans](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)\n",
    "\n",
    "Let's find out the groups of employees who left. You can observe that the most important factor for any employee to stay or leave is satisfaction and performance in the company. So let's bunch them in the group of people using cluster analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from pyclustertend import hopkins\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd = []\n",
    "\n",
    "K = range(2,10)\n",
    "\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(df_new)\n",
    "    ssd.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins(df_new, df_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(2, 10), ssd, \"bo-\")\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('ssd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame(-pd.Series(ssd).diff()).rename(index = lambda x : x+1)\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ssd).diff()[1:].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "visu = KElbowVisualizer(kmeans, k=(2,10))\n",
    "visu.fit(df_new)\n",
    "visu.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = range(2,10)\n",
    "for num_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(df_new)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(df_new, cluster_labels)\n",
    "    print(f\"For n_clusters={num_clusters}, the silhouette score is {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans = KMeans(n_clusters=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kmeans.fit(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = model_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5), dpi=100)\n",
    "sns.scatterplot(x= df_new['satisfaction_level'], y=df_new['last_evaluation'], hue=clusters, legend=False, alpha=0.5)\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_emp =  df[['satisfaction_level', 'last_evaluation']][df.left == 1]\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 0).fit(left_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_emp['label'] = kmeans.labels_\n",
    "\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "plt.scatter(left_emp['satisfaction_level'], left_emp['last_evaluation'], c=left_emp['label'], cmap='turbo')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.title('3 Clusters of employees who left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpmbaABr2snN"
   },
   "source": [
    "## 5. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYsKmaZd2snO"
   },
   "source": [
    "### Split Data as Train and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6b_dTvA2snQ"
   },
   "source": [
    "Here, Dataset is broken into two parts in ratio of 70:30. It means 70% data will used for model training and 30% for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S15Bpefl2snS"
   },
   "outputs": [],
   "source": [
    "X = df_new\n",
    "y = df.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Train features shape : \", X_train.shape)\n",
    "print(\"Train target shape   : \", y_train.shape)\n",
    "print(\"Test features shape  : \", X_test.shape)\n",
    "print(\"Test target shape    : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4d55Vek2snX"
   },
   "source": [
    "### #Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8OkbOrC2snY"
   },
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MefRCx542snY"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_model = gbc_model.fit(X_train, y_train)\n",
    "gbc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAiUMdtI2snk"
   },
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92xg3rvR2snl"
   },
   "source": [
    "- Confusion Matrix : You can use scikit-learn metrics module for accuracy calculation. A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making.\n",
    "\n",
    "    [Confusion Matrix](https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9VeChm62snm"
   },
   "source": [
    "- Yellowbrick: Yellowbrick is a suite of visualization and diagnostic tools that will enable quicker model selection. It’s a Python package that combines scikit-learn and matplotlib. Some of the more popular visualization tools include model selection, feature visualization, classification and regression visualization\n",
    "\n",
    "    [Yellowbrick](https://www.analyticsvidhya.com/blog/2018/05/yellowbrick-a-set-of-visualization-tools-to-accelerate-your-model-selection-process/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ber3WeUk2snn",
    "outputId": "c634b756-d466-4a59-b083-468a5ce04495"
   },
   "outputs": [],
   "source": [
    "y_pred= gbc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSUOz5302snx"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90HfPd4w2sn1"
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "plot_roc_curve(gbc_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.DataFrame(index=X.columns, data=gbc_model.feature_importances_, columns=['Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats = feats.sort_values(\"Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = imp_feats.sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "sns.barplot(data=imp_feats.sort_values('Importance'), y=imp_feats.sort_values('Importance').index, x='Importance', order=ord.index)\n",
    "\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9P157eX2sn2"
   },
   "source": [
    "### #KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPakx2ON2sn3"
   },
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPF_wziW2soC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkNI16f72sn4"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rates = []\n",
    "\n",
    "\n",
    "for k in range(1,10):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train) \n",
    "   \n",
    "    y_pred_test = knn_model.predict(X_test)\n",
    "    \n",
    "    test_error = 1-accuracy_score(y_test, y_pred_test)\n",
    "    test_error_rates.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=100)\n",
    "plt.plot(range(1,10), test_error_rates, color='blue', linestyle='--', marker='o', markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K_values')\n",
    "plt.ylabel('Error Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdGymWJ_2sn9"
   },
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BYTdWlr2soJ"
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfMy1D_p2soK"
   },
   "source": [
    "### #Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4GifMUw2soL"
   },
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhjBZQbu2soN"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRUPvrME2soc"
   },
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKLtTwJ82som"
   },
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdFUSrml2sop"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Modeling and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(random_state=42).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"satisfaction_level\": 0.50,\n",
    "           \"last_evaluation\": 0.25,\n",
    "           \"average_monthly_hours\": 120,\n",
    "           \"time_spent_company\": 3,\n",
    "           \"number_project\": 4,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = pd.DataFrame([my_dict])\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = pd.get_dummies(my_dict).reindex(columns=X.columns, fill_value=0)\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.predict(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv7E8XsazFMM"
   },
   "source": [
    "## 6. Model Deployment\n",
    "\n",
    "You cooked the food in the kitchen and moved on to the serving stage. The question is how do you showcase your work to others? Model Deployement helps you showcase your work to the world and make better decisions with it. But, deploying a model can get a little tricky at times. Before deploying the model, many things such as data storage, preprocessing, model building and monitoring need to be studied. Streamlit is a popular open source framework used by data scientists for model distribution.\n",
    "\n",
    "Deployment of machine learning models, means making your models available to your other business systems. By deploying models, other systems can send data to them and get their predictions, which are in turn populated back into the company systems. Through machine learning model deployment, can begin to take full advantage of the model you built.\n",
    "\n",
    "Data science is concerned with how to build machine learning models, which algorithm is more predictive, how to design features, and what variables to use to make the models more accurate. However, how these models are actually used is often neglected. And yet this is the most important step in the machine learning pipline. Only when a model is fully integrated with the business systems, real values ​​can be extract from its predictions.\n",
    "\n",
    "After doing the following operations in this notebook, jump to new .py file and create your web app with Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5pwXBOkJPeM"
   },
   "source": [
    "### Save and Export the Model as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(final_model, open(\"final_model_rf\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7sGSN6RJR6V"
   },
   "source": [
    "### Save and Export Variables as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WeQNcROJScb"
   },
   "outputs": [],
   "source": [
    "scaler_churn = scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler_churn, open(\"scaler_churn\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD6JV41czCKr"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Churn Prediction_Student_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
